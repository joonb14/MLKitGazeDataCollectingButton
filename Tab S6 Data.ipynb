{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/special/jbpark/TabS6/TabS6_00/',\n",
       " '/special/jbpark/TabS6/TabS6_02/',\n",
       " '/special/jbpark/TabS6/TabS6_03/']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import dlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "import random\n",
    "import cv2        \n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "target = \"/special/jbpark/TabS6/TabS6_0?/\"\n",
    "dir_list = glob.glob(target)\n",
    "dir_list.sort()\n",
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dir_list[0]+\"log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>gazeX</th>\n",
       "      <th>gazeY</th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "      <th>gyroX</th>\n",
       "      <th>gyroY</th>\n",
       "      <th>gyroZ</th>\n",
       "      <th>accelX</th>\n",
       "      <th>accelY</th>\n",
       "      <th>accelZ</th>\n",
       "      <th>eulerX</th>\n",
       "      <th>eulerY</th>\n",
       "      <th>eulerZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>110</td>\n",
       "      <td>-32.033745</td>\n",
       "      <td>0.365283</td>\n",
       "      <td>-0.012614</td>\n",
       "      <td>-0.000370</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.057458</td>\n",
       "      <td>8.355405</td>\n",
       "      <td>5.216741</td>\n",
       "      <td>8.994660</td>\n",
       "      <td>-2.228900</td>\n",
       "      <td>-1.577498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>110</td>\n",
       "      <td>-32.026720</td>\n",
       "      <td>0.369391</td>\n",
       "      <td>-0.007117</td>\n",
       "      <td>-0.000370</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.055064</td>\n",
       "      <td>8.355405</td>\n",
       "      <td>5.233500</td>\n",
       "      <td>9.053549</td>\n",
       "      <td>-2.946382</td>\n",
       "      <td>-1.607943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>110</td>\n",
       "      <td>-32.022785</td>\n",
       "      <td>0.372160</td>\n",
       "      <td>-0.005284</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.057458</td>\n",
       "      <td>8.353010</td>\n",
       "      <td>5.243076</td>\n",
       "      <td>8.868560</td>\n",
       "      <td>-2.125535</td>\n",
       "      <td>-1.808344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>110</td>\n",
       "      <td>-32.022260</td>\n",
       "      <td>0.374676</td>\n",
       "      <td>-0.000397</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.055064</td>\n",
       "      <td>8.355405</td>\n",
       "      <td>5.255047</td>\n",
       "      <td>9.021873</td>\n",
       "      <td>-2.196792</td>\n",
       "      <td>-1.513071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "      <td>110</td>\n",
       "      <td>-32.021664</td>\n",
       "      <td>0.375135</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>-0.000981</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.055064</td>\n",
       "      <td>8.353010</td>\n",
       "      <td>5.259835</td>\n",
       "      <td>9.174850</td>\n",
       "      <td>-2.299406</td>\n",
       "      <td>-1.339781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019</th>\n",
       "      <td>4019</td>\n",
       "      <td>1359</td>\n",
       "      <td>1706</td>\n",
       "      <td>-31.911673</td>\n",
       "      <td>0.311527</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.004581</td>\n",
       "      <td>0.055064</td>\n",
       "      <td>8.343434</td>\n",
       "      <td>5.247865</td>\n",
       "      <td>8.377969</td>\n",
       "      <td>-0.241953</td>\n",
       "      <td>-4.797105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>4020</td>\n",
       "      <td>1359</td>\n",
       "      <td>1706</td>\n",
       "      <td>-31.915625</td>\n",
       "      <td>0.334262</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>0.045488</td>\n",
       "      <td>8.355405</td>\n",
       "      <td>5.247865</td>\n",
       "      <td>6.889971</td>\n",
       "      <td>0.148847</td>\n",
       "      <td>-4.761093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4021</th>\n",
       "      <td>4021</td>\n",
       "      <td>1359</td>\n",
       "      <td>1706</td>\n",
       "      <td>-31.914938</td>\n",
       "      <td>0.335613</td>\n",
       "      <td>0.003089</td>\n",
       "      <td>-0.000447</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>0.047882</td>\n",
       "      <td>8.345828</td>\n",
       "      <td>5.238288</td>\n",
       "      <td>7.281829</td>\n",
       "      <td>0.311755</td>\n",
       "      <td>-4.679541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4022</th>\n",
       "      <td>4022</td>\n",
       "      <td>1359</td>\n",
       "      <td>1706</td>\n",
       "      <td>-31.912228</td>\n",
       "      <td>0.348581</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>0.050276</td>\n",
       "      <td>8.350616</td>\n",
       "      <td>5.231106</td>\n",
       "      <td>6.632558</td>\n",
       "      <td>0.106703</td>\n",
       "      <td>-4.729524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023</th>\n",
       "      <td>4023</td>\n",
       "      <td>1359</td>\n",
       "      <td>1706</td>\n",
       "      <td>-31.912537</td>\n",
       "      <td>0.347602</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>-0.000447</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>0.047882</td>\n",
       "      <td>8.350616</td>\n",
       "      <td>5.233500</td>\n",
       "      <td>6.208428</td>\n",
       "      <td>0.296154</td>\n",
       "      <td>-4.907534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4024 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      count  gazeX  gazeY      pitch      roll     gyroX     gyroY     gyroZ  \\\n",
       "0         0     79    110 -32.033745  0.365283 -0.012614 -0.000370  0.000244   \n",
       "1         1     79    110 -32.026720  0.369391 -0.007117 -0.000370  0.000855   \n",
       "2         2     79    110 -32.022785  0.372160 -0.005284  0.000241  0.000244   \n",
       "3         3     79    110 -32.022260  0.374676 -0.000397  0.000241  0.000244   \n",
       "4         4     79    110 -32.021664  0.375135  0.000214 -0.000981  0.000244   \n",
       "...     ...    ...    ...        ...       ...       ...       ...       ...   \n",
       "4019   4019   1359   1706 -31.911673  0.311527  0.006143  0.000164  0.004581   \n",
       "4020   4020   1359   1706 -31.915625  0.334262  0.004921  0.000164  0.003971   \n",
       "4021   4021   1359   1706 -31.914938  0.335613  0.003089 -0.000447  0.005803   \n",
       "4022   4022   1359   1706 -31.912228  0.348581  0.001256  0.000164  0.003360   \n",
       "4023   4023   1359   1706 -31.912537  0.347602  0.001867 -0.000447  0.007025   \n",
       "\n",
       "        accelX    accelY    accelZ    eulerX    eulerY    eulerZ  \n",
       "0     0.057458  8.355405  5.216741  8.994660 -2.228900 -1.577498  \n",
       "1     0.055064  8.355405  5.233500  9.053549 -2.946382 -1.607943  \n",
       "2     0.057458  8.353010  5.243076  8.868560 -2.125535 -1.808344  \n",
       "3     0.055064  8.355405  5.255047  9.021873 -2.196792 -1.513071  \n",
       "4     0.055064  8.353010  5.259835  9.174850 -2.299406 -1.339781  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "4019  0.055064  8.343434  5.247865  8.377969 -0.241953 -4.797105  \n",
       "4020  0.045488  8.355405  5.247865  6.889971  0.148847 -4.761093  \n",
       "4021  0.047882  8.345828  5.238288  7.281829  0.311755 -4.679541  \n",
       "4022  0.050276  8.350616  5.231106  6.632558  0.106703 -4.729524  \n",
       "4023  0.047882  8.350616  5.233500  6.208428  0.296154 -4.907534  \n",
       "\n",
       "[4024 rows x 14 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4024"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = df[\"count\"].tolist()\n",
    "len(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "for dir_name in dir_list:\n",
    "    df = pd.read_csv(dir_name+\"log.csv\")\n",
    "    file_name = df[\"count\"].tolist()\n",
    "    facegrid = np.genfromtxt (dir_name+\"facegrid/\"+str(file_name[0]).zfill(5)+\".csv\", delimiter=\",\")\n",
    "    plt.imshow(facegrid, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=224x224 at 0x7EFE5D622690>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = Image.open(target+\"lefteye/\"+str(file_name[0]).zfill(5)+\".jpg\").convert(\"L\")\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gazeX = df[\"gazeX\"].tolist()\n",
    "gazeY = df[\"gazeY\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eulerX = df[\"eulerX\"].tolist()\n",
    "eulerY = df[\"eulerY\"].tolist()\n",
    "eulerZ = df[\"eulerZ\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import dlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "import random\n",
    "import cv2        \n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "dir_list = [\"/special/jbpark/TabS6/TabS6_04/\", \n",
    "            \"/special/jbpark/TabS6/TabS6_05/\", \n",
    "            \"/special/jbpark/TabS6/TabS6_06/\",\n",
    "           \"/special/jbpark/TabS6/TabS6_07/\",\n",
    "           \"/special/jbpark/TabS6/TabS6_08/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_eye = []\n",
    "right_eye = []\n",
    "gaze_point = []\n",
    "gaze_point = []\n",
    "euler = []\n",
    "face_grid = []\n",
    "left_eye_grid = []\n",
    "right_eye_grid = []\n",
    "facepos = []\n",
    "\n",
    "image_type = \"L\"\n",
    "\n",
    "for dir_name in dir_list:\n",
    "    df = pd.read_csv(dir_name+\"log.csv\")\n",
    "    file_name = df[\"count\"].tolist()\n",
    "    im = Image.open(dir_name+\"lefteye/\"+str(file_name[0]).zfill(5)+\".jpg\").convert(image_type)\n",
    "    gazeX = df[\"gazeX\"].tolist()\n",
    "    gazeY = df[\"gazeY\"].tolist()\n",
    "    eulerX = df[\"eulerX\"].tolist()\n",
    "    eulerY = df[\"eulerY\"].tolist()\n",
    "    eulerZ = df[\"eulerZ\"].tolist()\n",
    "    faceX = df[\"faceX\"].tolist()\n",
    "    faceY = df[\"faceY\"].tolist()\n",
    "    \n",
    "    resolution=64\n",
    "    \n",
    "    for i in range(len(file_name)):\n",
    "        left_eye_image = np.asarray(Image.open(dir_name+\"lefteye/\"+str(file_name[i]).zfill(5)+\".jpg\").convert(image_type).resize((resolution,resolution)))/255\n",
    "        right_eye_image = np.asarray(Image.open(dir_name+\"righteye/\"+str(file_name[i]).zfill(5)+\".jpg\").convert(image_type).resize((resolution,resolution)))/255\n",
    "        left_eye.append(left_eye_image)\n",
    "        right_eye.append(right_eye_image)\n",
    "        facegrid = np.genfromtxt (dir_name+\"facegrid/\"+str(file_name[i]).zfill(5)+\".csv\", delimiter=\",\")\n",
    "        face_grid.append(facegrid)\n",
    "        lefteyegrid = np.genfromtxt (dir_name+\"lefteyegrid/\"+str(file_name[i]).zfill(5)+\".csv\", delimiter=\",\")\n",
    "        left_eye_grid.append(lefteyegrid)\n",
    "        righteyegrid = np.genfromtxt (dir_name+\"righteyegrid/\"+str(file_name[i]).zfill(5)+\".csv\", delimiter=\",\")\n",
    "        right_eye_grid.append(righteyegrid)\n",
    "        gaze_point.append([int(gazeX[i]),int(gazeY[i])])\n",
    "        euler.append([float(eulerX[i]), float(eulerY[i]), float(eulerZ[i])])\n",
    "        facepos.append([float(faceX[i]), float(faceY[i])])\n",
    "left_eye = np.asarray(left_eye)\n",
    "right_eye = np.asarray(right_eye)\n",
    "gaze_point = np.asarray(gaze_point)\n",
    "face_grid = np.asarray(face_grid)\n",
    "left_eye_grid = np.asarray(left_eye_grid)\n",
    "right_eye_grid = np.asarray(right_eye_grid)\n",
    "euler = np.asarray(euler)\n",
    "facepos = np.asarray(facepos)\n",
    "\n",
    "save_dir=\"/special/jbpark/TabS6illumdata/TabS6_facepos/\"\n",
    "Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "             \n",
    "#save to File\n",
    "np.save(save_dir+\"gaze_point.npy\",gaze_point)\n",
    "np.save(save_dir+\"left_eye.npy\",left_eye)\n",
    "np.save(save_dir+\"right_eye.npy\",right_eye)\n",
    "np.save(save_dir+\"face_grid.npy\",face_grid)\n",
    "np.save(save_dir+\"left_eye_grid.npy\",left_eye_grid)\n",
    "np.save(save_dir+\"right_eye_grid.npy\",right_eye_grid)\n",
    "np.save(save_dir+\"euler.npy\",euler)\n",
    "np.save(save_dir+\"facepos.npy\",facepos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28092"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gaze_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28092, 50, 50)\n",
      "(28092, 50, 50)\n",
      "(28092, 25, 25)\n",
      "(28092, 2)\n"
     ]
    }
   ],
   "source": [
    "print(right_eye_grid.shape)\n",
    "print(left_eye_grid.shape)\n",
    "print(face_grid.shape)\n",
    "print(facepos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lvmdata/jbpark/.anaconda3/envs/tensorflow20/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "split_length = int(len(gaze_point)*0.9)\n",
    "target_list = []\n",
    "for i in range(len(gaze_point)):\n",
    "    target_list.append([left_eye[i], right_eye[i], gaze_point[i], euler[i], face_grid[i], left_eye_grid[i], right_eye_grid[i], facepos[i]])\n",
    "\n",
    "random.shuffle(target_list)\n",
    "\n",
    "train_data = target_list[:split_length]\n",
    "test_data = target_list[split_length:]\n",
    "np_train_data = np.asarray(train_data)\n",
    "np_test_data = np.asarray(test_data)\n",
    "\n",
    "train_left_eye_list=[]\n",
    "train_right_eye_list=[]\n",
    "train_gaze_point_list=[]\n",
    "train_euler_list=[]\n",
    "train_face_grid=[]\n",
    "train_left_eye_grid=[]\n",
    "train_right_eye_grid=[]\n",
    "train_facepos=[]\n",
    "\n",
    "for i in range(len(np_train_data)):\n",
    "    train_left_eye_list.append(np_train_data[i][0])\n",
    "    train_right_eye_list.append(np_train_data[i][1])\n",
    "    train_gaze_point_list.append(np_train_data[i][2])\n",
    "    train_euler_list.append(np_train_data[i][3])\n",
    "    train_face_grid.append(np_train_data[i][4])\n",
    "    train_left_eye_grid.append(np_train_data[i][5])\n",
    "    train_right_eye_grid.append(np_train_data[i][6])\n",
    "    train_facepos.append(np_train_data[i][7])\n",
    "    \n",
    "test_left_eye_list=[]\n",
    "test_right_eye_list=[]\n",
    "test_gaze_point_list=[]\n",
    "test_euler_list=[]\n",
    "test_face_grid=[]\n",
    "test_left_eye_grid=[]\n",
    "test_right_eye_grid=[]\n",
    "test_facepos=[]\n",
    "\n",
    "for i in range(len(np_test_data)):\n",
    "    test_left_eye_list.append(np_test_data[i][0])\n",
    "    test_right_eye_list.append(np_test_data[i][1])\n",
    "    test_gaze_point_list.append(np_test_data[i][2])\n",
    "    test_euler_list.append(np_test_data[i][3])\n",
    "    test_face_grid.append(np_test_data[i][4])\n",
    "    test_left_eye_grid.append(np_test_data[i][5])\n",
    "    test_right_eye_grid.append(np_test_data[i][6])\n",
    "    test_facepos.append(np_test_data[i][7])\n",
    "\n",
    "np_train_gaze_point_list = np.asarray(train_gaze_point_list)\n",
    "np_train_right_eye_list = np.asarray(train_right_eye_list)\n",
    "np_train_left_eye_list = np.asarray(train_left_eye_list)\n",
    "np_train_euler_list = np.asarray(train_euler_list)\n",
    "np_train_face_grid = np.asarray(train_face_grid)\n",
    "np_train_left_eye_grid = np.asarray(train_left_eye_grid)\n",
    "np_train_right_eye_grid = np.asarray(train_right_eye_grid)\n",
    "np_train_facepos = np.asarray(train_facepos)\n",
    "\n",
    "np_test_gaze_point_list = np.asarray(test_gaze_point_list)\n",
    "np_test_right_eye_list = np.asarray(test_right_eye_list)\n",
    "np_test_left_eye_list = np.asarray(test_left_eye_list)\n",
    "np_test_euler_list = np.asarray(test_euler_list)\n",
    "np_test_face_grid = np.asarray(test_face_grid)\n",
    "np_test_left_eye_grid = np.asarray(test_left_eye_grid)\n",
    "np_test_right_eye_grid = np.asarray(test_right_eye_grid)\n",
    "np_test_facepos = np.asarray(test_facepos)\n",
    "\n",
    "train_dir=\"/special/jbpark/TabS6illumdata/TabS6_facepos/train_dataset/\"\n",
    "Path(train_dir).mkdir(parents=True, exist_ok=True)\n",
    "test_dir=\"/special/jbpark/TabS6illumdata/TabS6_facepos/test_dataset/\"\n",
    "Path(test_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(train_dir+\"gaze_point.npy\",np_train_gaze_point_list)\n",
    "np.save(train_dir+\"left_eye.npy\",np_train_left_eye_list)\n",
    "np.save(train_dir+\"right_eye.npy\",np_train_right_eye_list)\n",
    "np.save(train_dir+\"euler.npy\",np_train_euler_list)\n",
    "np.save(train_dir+\"face_grid.npy\",np_train_face_grid)\n",
    "np.save(train_dir+\"left_eye_grid.npy\",np_train_left_eye_grid)\n",
    "np.save(train_dir+\"right_eye_grid.npy\",np_train_right_eye_grid)\n",
    "np.save(train_dir+\"facepos.npy\",np_train_facepos)\n",
    "\n",
    "\n",
    "np.save(test_dir+\"gaze_point.npy\",np_test_gaze_point_list)\n",
    "np.save(test_dir+\"left_eye.npy\",np_test_left_eye_list)\n",
    "np.save(test_dir+\"right_eye.npy\",np_test_right_eye_list)\n",
    "np.save(test_dir+\"euler.npy\",np_test_euler_list)\n",
    "np.save(test_dir+\"face_grid.npy\",np_test_face_grid)\n",
    "np.save(test_dir+\"left_eye_grid.npy\",np_test_left_eye_grid)\n",
    "np.save(test_dir+\"right_eye_grid.npy\",np_test_right_eye_grid)\n",
    "np.save(test_dir+\"facepos.npy\",np_test_facepos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Shape:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"Shape_1:0\", shape=(2,), dtype=int32)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "left_eye (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "right_eye (InputLayer)          [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 32)   320         left_eye[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 32)   320         right_eye[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 64)   18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 64)   18496       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 128)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 128)  73856       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 128)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 128)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 8192)         0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 8192)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "face_grid (InputLayer)          [(None, 25, 25, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "euler (InputLayer)              [(None, 1, 1, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16384)        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 625)          0           face_grid[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 1, 3)      12          euler[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "facepos (InputLayer)            [(None, 1, 1, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          4194560     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           10016       flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 3)            0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2)            0           facepos[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 21)           0           dense_2[0][0]                    \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          32896       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           1408        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 192)          0           dense_4[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pred (Dense)                    (None, 2)            386         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2)            0           pred[0][0]                       \n",
      "                                                                 flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,424,622\n",
      "Trainable params: 4,424,622\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 22753 samples, validate on 2529 samples\n",
      "Epoch 1/1000\n",
      "22753/22753 [==============================] - 10s 443us/sample - loss: 153184.6178 - val_loss: 32468.8325\n",
      "Epoch 2/1000\n",
      "22753/22753 [==============================] - 8s 365us/sample - loss: 19371.1334 - val_loss: 29291.6523\n",
      "Epoch 3/1000\n",
      "22753/22753 [==============================] - 8s 369us/sample - loss: 12743.5532 - val_loss: 10013.3970\n",
      "Epoch 4/1000\n",
      "22753/22753 [==============================] - 8s 338us/sample - loss: 9972.4708 - val_loss: 10517.9520\n",
      "Epoch 5/1000\n",
      "22753/22753 [==============================] - 8s 364us/sample - loss: 8355.1936 - val_loss: 6742.2695\n",
      "Epoch 6/1000\n",
      "22753/22753 [==============================] - 7s 328us/sample - loss: 7309.7216 - val_loss: 8576.6088\n",
      "Epoch 7/1000\n",
      "22753/22753 [==============================] - 8s 332us/sample - loss: 6634.6133 - val_loss: 13316.0274\n",
      "Epoch 8/1000\n",
      "22753/22753 [==============================] - 8s 363us/sample - loss: 5932.1313 - val_loss: 6225.6417\n",
      "Epoch 9/1000\n",
      "22753/22753 [==============================] - 8s 332us/sample - loss: 5285.4764 - val_loss: 12730.0939\n",
      "Epoch 10/1000\n",
      "22753/22753 [==============================] - 8s 347us/sample - loss: 5354.3669 - val_loss: 4932.1404\n",
      "Epoch 11/1000\n",
      "22753/22753 [==============================] - 7s 329us/sample - loss: 4516.9461 - val_loss: 5252.6903\n",
      "Epoch 12/1000\n",
      "22753/22753 [==============================] - 7s 327us/sample - loss: 4675.0057 - val_loss: 6082.3926\n",
      "Epoch 13/1000\n",
      "22753/22753 [==============================] - 8s 331us/sample - loss: 4294.1136 - val_loss: 10647.0686\n",
      "Epoch 14/1000\n",
      "22753/22753 [==============================] - 8s 345us/sample - loss: 4047.6276 - val_loss: 3371.7177\n",
      "Epoch 15/1000\n",
      "22753/22753 [==============================] - 7s 329us/sample - loss: 3823.4533 - val_loss: 7155.2163\n",
      "Epoch 16/1000\n",
      "22753/22753 [==============================] - 8s 330us/sample - loss: 3810.6918 - val_loss: 3823.4016\n",
      "Epoch 17/1000\n",
      "22753/22753 [==============================] - 8s 355us/sample - loss: 3532.9246 - val_loss: 2922.1737\n",
      "Epoch 18/1000\n",
      "22753/22753 [==============================] - 8s 331us/sample - loss: 3361.5261 - val_loss: 3264.5588\n",
      "Epoch 19/1000\n",
      "22753/22753 [==============================] - 7s 328us/sample - loss: 3040.8270 - val_loss: 4093.8397\n",
      "Epoch 20/1000\n",
      "22753/22753 [==============================] - 7s 328us/sample - loss: 3202.9014 - val_loss: 3825.6181\n",
      "Epoch 21/1000\n",
      "22753/22753 [==============================] - 8s 343us/sample - loss: 2904.2841 - val_loss: 2723.7505\n",
      "Epoch 22/1000\n",
      "22753/22753 [==============================] - 7s 329us/sample - loss: 2994.8053 - val_loss: 3760.6346\n",
      "Epoch 23/1000\n",
      "22753/22753 [==============================] - 7s 328us/sample - loss: 2875.6671 - val_loss: 3228.4526\n",
      "Epoch 24/1000\n",
      "22753/22753 [==============================] - 7s 329us/sample - loss: 2752.2870 - val_loss: 4204.1955\n",
      "Epoch 25/1000\n",
      "22753/22753 [==============================] - 7s 329us/sample - loss: 2639.9584 - val_loss: 6610.4327\n",
      "Epoch 26/1000\n",
      "22753/22753 [==============================] - 7s 329us/sample - loss: 2620.6727 - val_loss: 4794.8753\n",
      "Epoch 27/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 2568.1818 - val_loss: 3762.7581\n",
      "Epoch 28/1000\n",
      "22753/22753 [==============================] - 8s 354us/sample - loss: 2445.2698 - val_loss: 2625.5710\n",
      "Epoch 29/1000\n",
      "22753/22753 [==============================] - 7s 329us/sample - loss: 2366.5748 - val_loss: 2710.6413\n",
      "Epoch 30/1000\n",
      "22753/22753 [==============================] - 7s 329us/sample - loss: 2380.7188 - val_loss: 4338.5550\n",
      "Epoch 31/1000\n",
      "22753/22753 [==============================] - 7s 329us/sample - loss: 2251.3029 - val_loss: 2975.9301\n",
      "Epoch 32/1000\n",
      "22753/22753 [==============================] - 8s 352us/sample - loss: 2242.1223 - val_loss: 2607.6782\n",
      "Epoch 33/1000\n",
      "22753/22753 [==============================] - 8s 340us/sample - loss: 2101.4252 - val_loss: 2797.0436\n",
      "Epoch 34/1000\n",
      "22753/22753 [==============================] - 8s 330us/sample - loss: 2172.4867 - val_loss: 3044.1730\n",
      "Epoch 35/1000\n",
      "22753/22753 [==============================] - 8s 333us/sample - loss: 1993.0322 - val_loss: 3553.2397\n",
      "Epoch 36/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 2017.5121 - val_loss: 3408.1502\n",
      "Epoch 37/1000\n",
      "22753/22753 [==============================] - 8s 352us/sample - loss: 1985.7783 - val_loss: 2198.0604\n",
      "Epoch 38/1000\n",
      "22753/22753 [==============================] - 8s 333us/sample - loss: 2000.8635 - val_loss: 2935.8627\n",
      "Epoch 39/1000\n",
      "22753/22753 [==============================] - 8s 331us/sample - loss: 1864.7445 - val_loss: 2443.2551\n",
      "Epoch 40/1000\n",
      "22753/22753 [==============================] - 8s 331us/sample - loss: 1863.6987 - val_loss: 3796.4077\n",
      "Epoch 41/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 1879.5475 - val_loss: 3281.9475\n",
      "Epoch 42/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 1859.1445 - val_loss: 3064.6979\n",
      "Epoch 43/1000\n",
      "22753/22753 [==============================] - 8s 332us/sample - loss: 1763.7538 - val_loss: 3938.5047\n",
      "Epoch 44/1000\n",
      "22753/22753 [==============================] - 8s 350us/sample - loss: 1717.0089 - val_loss: 1919.7542\n",
      "Epoch 45/1000\n",
      "22753/22753 [==============================] - 8s 333us/sample - loss: 1713.9826 - val_loss: 2083.3707\n",
      "Epoch 46/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 1659.6292 - val_loss: 2551.7556\n",
      "Epoch 47/1000\n",
      "22753/22753 [==============================] - 8s 331us/sample - loss: 1664.9875 - val_loss: 2876.0766\n",
      "Epoch 48/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 1605.8720 - val_loss: 3237.6561\n",
      "Epoch 49/1000\n",
      "22753/22753 [==============================] - 8s 353us/sample - loss: 1517.9101 - val_loss: 1862.8131\n",
      "Epoch 50/1000\n",
      "22753/22753 [==============================] - 8s 339us/sample - loss: 1626.0474 - val_loss: 2165.6196\n",
      "Epoch 51/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 1516.3353 - val_loss: 2258.8025\n",
      "Epoch 52/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 1461.4429 - val_loss: 2478.9593\n",
      "Epoch 53/1000\n",
      "22753/22753 [==============================] - 8s 333us/sample - loss: 1510.5929 - val_loss: 2169.3042\n",
      "Epoch 54/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 1469.2105 - val_loss: 4492.0353\n",
      "Epoch 55/1000\n",
      "22753/22753 [==============================] - 8s 357us/sample - loss: 1515.7174 - val_loss: 1808.1958\n",
      "Epoch 56/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 1388.3067 - val_loss: 3017.7622\n",
      "Epoch 57/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 1424.0509 - val_loss: 2055.3351\n",
      "Epoch 58/1000\n",
      "22753/22753 [==============================] - 8s 333us/sample - loss: 1433.9482 - val_loss: 1922.6077\n",
      "Epoch 59/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 1399.7431 - val_loss: 2027.0107\n",
      "Epoch 60/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 1315.8138 - val_loss: 3365.7328\n",
      "Epoch 61/1000\n",
      "22753/22753 [==============================] - 8s 354us/sample - loss: 1325.4445 - val_loss: 1569.8188\n",
      "Epoch 62/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 1281.6562 - val_loss: 1767.7168\n",
      "Epoch 63/1000\n",
      "22753/22753 [==============================] - 8s 340us/sample - loss: 1264.8989 - val_loss: 3280.8750\n",
      "Epoch 64/1000\n",
      "22753/22753 [==============================] - 8s 340us/sample - loss: 1341.4392 - val_loss: 3122.9345\n",
      "Epoch 65/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 1313.0441 - val_loss: 2040.9046\n",
      "Epoch 66/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 1164.5900 - val_loss: 1705.8855\n",
      "Epoch 67/1000\n",
      "22753/22753 [==============================] - 8s 338us/sample - loss: 1230.1180 - val_loss: 2344.1973\n",
      "Epoch 68/1000\n",
      "22753/22753 [==============================] - 8s 339us/sample - loss: 1169.0857 - val_loss: 2425.5160\n",
      "Epoch 69/1000\n",
      "22753/22753 [==============================] - 8s 357us/sample - loss: 1221.9533 - val_loss: 1481.0890\n",
      "Epoch 70/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 1127.6696 - val_loss: 3200.7005\n",
      "Epoch 71/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 1122.6042 - val_loss: 3864.9397\n",
      "Epoch 72/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 1156.7551 - val_loss: 2150.2104\n",
      "Epoch 73/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 1120.2376 - val_loss: 1863.8806\n",
      "Epoch 74/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 1151.2766 - val_loss: 1945.5147\n",
      "Epoch 75/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22753/22753 [==============================] - 8s 334us/sample - loss: 1089.9660 - val_loss: 6131.5705\n",
      "Epoch 76/1000\n",
      "22753/22753 [==============================] - 8s 355us/sample - loss: 1324.6966 - val_loss: 1390.1246\n",
      "Epoch 77/1000\n",
      "22753/22753 [==============================] - 8s 341us/sample - loss: 1028.4920 - val_loss: 1408.2737\n",
      "Epoch 78/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 1001.8475 - val_loss: 1657.0131\n",
      "Epoch 79/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 1039.2800 - val_loss: 3067.2496\n",
      "Epoch 80/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 1089.3420 - val_loss: 1701.3327\n",
      "Epoch 81/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 984.4458 - val_loss: 2664.8015\n",
      "Epoch 82/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 986.3201 - val_loss: 2119.8992\n",
      "Epoch 83/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 984.8068 - val_loss: 1915.3726\n",
      "Epoch 84/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 985.9307 - val_loss: 3302.9231\n",
      "Epoch 85/1000\n",
      "22753/22753 [==============================] - 8s 344us/sample - loss: 942.7005 - val_loss: 2251.3430\n",
      "Epoch 86/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 936.4534 - val_loss: 3503.8719\n",
      "Epoch 87/1000\n",
      "22753/22753 [==============================] - 8s 332us/sample - loss: 949.6238 - val_loss: 2871.7238\n",
      "Epoch 88/1000\n",
      "22753/22753 [==============================] - 7s 326us/sample - loss: 965.9906 - val_loss: 2017.2359\n",
      "Epoch 89/1000\n",
      "22753/22753 [==============================] - 7s 325us/sample - loss: 873.0283 - val_loss: 2888.1361\n",
      "Epoch 90/1000\n",
      "22753/22753 [==============================] - 7s 326us/sample - loss: 947.4988 - val_loss: 1593.9615\n",
      "Epoch 91/1000\n",
      "22753/22753 [==============================] - 7s 330us/sample - loss: 903.5959 - val_loss: 1404.4536\n",
      "Epoch 92/1000\n",
      "22753/22753 [==============================] - 8s 330us/sample - loss: 852.6128 - val_loss: 1574.1932\n",
      "Epoch 93/1000\n",
      "22753/22753 [==============================] - 7s 327us/sample - loss: 833.9772 - val_loss: 1614.0586\n",
      "Epoch 94/1000\n",
      "22753/22753 [==============================] - 8s 330us/sample - loss: 867.0970 - val_loss: 1408.3974\n",
      "Epoch 95/1000\n",
      "22753/22753 [==============================] - 7s 329us/sample - loss: 858.5775 - val_loss: 1741.4462\n",
      "Epoch 96/1000\n",
      "22753/22753 [==============================] - 7s 329us/sample - loss: 792.1845 - val_loss: 1736.5004\n",
      "Epoch 97/1000\n",
      "22753/22753 [==============================] - 8s 330us/sample - loss: 805.5827 - val_loss: 1743.3008\n",
      "Epoch 98/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 852.1822 - val_loss: 1924.2618\n",
      "Epoch 99/1000\n",
      "22753/22753 [==============================] - 7s 330us/sample - loss: 761.5715 - val_loss: 1809.8580\n",
      "Epoch 100/1000\n",
      "22753/22753 [==============================] - 8s 355us/sample - loss: 803.6645 - val_loss: 1274.0803\n",
      "Epoch 101/1000\n",
      "22753/22753 [==============================] - 8s 332us/sample - loss: 774.7010 - val_loss: 1319.5058\n",
      "Epoch 102/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 783.3895 - val_loss: 1715.4892\n",
      "Epoch 103/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 786.6636 - val_loss: 1433.8224\n",
      "Epoch 104/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 747.5322 - val_loss: 1943.8953\n",
      "Epoch 105/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 752.8126 - val_loss: 1643.7802\n",
      "Epoch 106/1000\n",
      "22753/22753 [==============================] - 8s 354us/sample - loss: 731.8314 - val_loss: 1262.5486\n",
      "Epoch 107/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 715.7535 - val_loss: 1618.2007\n",
      "Epoch 108/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 705.7015 - val_loss: 1387.9228\n",
      "Epoch 109/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 705.0143 - val_loss: 1792.1622\n",
      "Epoch 110/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 765.3532 - val_loss: 1263.9017\n",
      "Epoch 111/1000\n",
      "22753/22753 [==============================] - 8s 341us/sample - loss: 656.6134 - val_loss: 1388.7531\n",
      "Epoch 112/1000\n",
      "22753/22753 [==============================] - 8s 338us/sample - loss: 687.3765 - val_loss: 1590.5660\n",
      "Epoch 113/1000\n",
      "22753/22753 [==============================] - 8s 338us/sample - loss: 649.0890 - val_loss: 1704.8161\n",
      "Epoch 114/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 676.0637 - val_loss: 1626.9938\n",
      "Epoch 115/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 667.4115 - val_loss: 2084.7366\n",
      "Epoch 116/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 656.0818 - val_loss: 1867.9419\n",
      "Epoch 117/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 642.1843 - val_loss: 4160.4054\n",
      "Epoch 118/1000\n",
      "22753/22753 [==============================] - 8s 339us/sample - loss: 753.0473 - val_loss: 1368.3502\n",
      "Epoch 119/1000\n",
      "22753/22753 [==============================] - 8s 341us/sample - loss: 568.1507 - val_loss: 1795.4923\n",
      "Epoch 120/1000\n",
      "22753/22753 [==============================] - 8s 339us/sample - loss: 643.7389 - val_loss: 2301.0515\n",
      "Epoch 121/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 720.2763 - val_loss: 1578.9409\n",
      "Epoch 122/1000\n",
      "22753/22753 [==============================] - 8s 338us/sample - loss: 583.0188 - val_loss: 1521.1860\n",
      "Epoch 123/1000\n",
      "22753/22753 [==============================] - 8s 352us/sample - loss: 604.0546 - val_loss: 1228.5418\n",
      "Epoch 124/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 642.4971 - val_loss: 1422.7676\n",
      "Epoch 125/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 552.6512 - val_loss: 1454.0755\n",
      "Epoch 126/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 593.6423 - val_loss: 1582.0729\n",
      "Epoch 127/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 575.1512 - val_loss: 1487.9153\n",
      "Epoch 128/1000\n",
      "22753/22753 [==============================] - 8s 339us/sample - loss: 616.5554 - val_loss: 1356.7508\n",
      "Epoch 129/1000\n",
      "22753/22753 [==============================] - 8s 346us/sample - loss: 529.1028 - val_loss: 1898.3057\n",
      "Epoch 130/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 580.6358 - val_loss: 2956.8806\n",
      "Epoch 131/1000\n",
      "22753/22753 [==============================] - 8s 354us/sample - loss: 594.8280 - val_loss: 1195.4797\n",
      "Epoch 132/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 519.4023 - val_loss: 2376.1099\n",
      "Epoch 133/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 556.1845 - val_loss: 2334.4560\n",
      "Epoch 134/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 549.8763 - val_loss: 1490.1369\n",
      "Epoch 135/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 544.7863 - val_loss: 1202.8041\n",
      "Epoch 136/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 523.4137 - val_loss: 1386.3645\n",
      "Epoch 137/1000\n",
      "22753/22753 [==============================] - 8s 338us/sample - loss: 510.0682 - val_loss: 1893.2318\n",
      "Epoch 138/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 510.3797 - val_loss: 1458.4176\n",
      "Epoch 139/1000\n",
      "22753/22753 [==============================] - 8s 349us/sample - loss: 487.2286 - val_loss: 1157.3089\n",
      "Epoch 140/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 475.4889 - val_loss: 1619.7629\n",
      "Epoch 141/1000\n",
      "22753/22753 [==============================] - 8s 342us/sample - loss: 496.9262 - val_loss: 1972.1288\n",
      "Epoch 142/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 482.8595 - val_loss: 1933.1857\n",
      "Epoch 143/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 487.9016 - val_loss: 1444.0066\n",
      "Epoch 144/1000\n",
      "22753/22753 [==============================] - 8s 338us/sample - loss: 480.5970 - val_loss: 1172.3634\n",
      "Epoch 145/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 458.5095 - val_loss: 1895.4199\n",
      "Epoch 146/1000\n",
      "22753/22753 [==============================] - 8s 333us/sample - loss: 526.3640 - val_loss: 1333.4420\n",
      "Epoch 147/1000\n",
      "22753/22753 [==============================] - 8s 349us/sample - loss: 445.1005 - val_loss: 1110.4348\n",
      "Epoch 148/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 448.0590 - val_loss: 2177.8877\n",
      "Epoch 149/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 554.0657 - val_loss: 1482.3489\n",
      "Epoch 150/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 422.9890 - val_loss: 1510.9215\n",
      "Epoch 151/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 421.4657 - val_loss: 1489.4605\n",
      "Epoch 152/1000\n",
      "22753/22753 [==============================] - 8s 338us/sample - loss: 485.2104 - val_loss: 1937.1828\n",
      "Epoch 153/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 505.9362 - val_loss: 2587.7401\n",
      "Epoch 154/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 442.2038 - val_loss: 1279.5473\n",
      "Epoch 155/1000\n",
      "22753/22753 [==============================] - 8s 339us/sample - loss: 407.7734 - val_loss: 1657.1575\n",
      "Epoch 156/1000\n",
      "22753/22753 [==============================] - 8s 344us/sample - loss: 432.3193 - val_loss: 1824.8873\n",
      "Epoch 157/1000\n",
      "22753/22753 [==============================] - 8s 338us/sample - loss: 424.7662 - val_loss: 1215.1243\n",
      "Epoch 158/1000\n",
      "22753/22753 [==============================] - 8s 338us/sample - loss: 418.3928 - val_loss: 1252.5579\n",
      "Epoch 159/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 415.7861 - val_loss: 2189.3467\n",
      "Epoch 160/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 413.6793 - val_loss: 1761.0818\n",
      "Epoch 161/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 444.0278 - val_loss: 1462.6025\n",
      "Epoch 162/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 370.6371 - val_loss: 1344.3292\n",
      "Epoch 163/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 437.3804 - val_loss: 1672.6959\n",
      "Epoch 164/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 404.4025 - val_loss: 2142.2592\n",
      "Epoch 165/1000\n",
      "22753/22753 [==============================] - 8s 333us/sample - loss: 405.4565 - val_loss: 1430.9807\n",
      "Epoch 166/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 372.8846 - val_loss: 2097.1614\n",
      "Epoch 167/1000\n",
      "22753/22753 [==============================] - 8s 339us/sample - loss: 407.9515 - val_loss: 1501.2822\n",
      "Epoch 168/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 402.5953 - val_loss: 1454.4946\n",
      "Epoch 169/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 398.9676 - val_loss: 1943.9324\n",
      "Epoch 170/1000\n",
      "22753/22753 [==============================] - 8s 343us/sample - loss: 388.8653 - val_loss: 1178.9410\n",
      "Epoch 171/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 339.0179 - val_loss: 1176.2032\n",
      "Epoch 172/1000\n",
      "22753/22753 [==============================] - 8s 338us/sample - loss: 366.9829 - val_loss: 1209.4586\n",
      "Epoch 173/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 377.4765 - val_loss: 1293.1999\n",
      "Epoch 174/1000\n",
      "22753/22753 [==============================] - 8s 338us/sample - loss: 385.8482 - val_loss: 1291.4403\n",
      "Epoch 175/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 351.0081 - val_loss: 1422.0474\n",
      "Epoch 176/1000\n",
      "22753/22753 [==============================] - 8s 339us/sample - loss: 353.8137 - val_loss: 1335.9158\n",
      "Epoch 177/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 381.0468 - val_loss: 1248.2616\n",
      "Epoch 178/1000\n",
      "22753/22753 [==============================] - 8s 339us/sample - loss: 340.1076 - val_loss: 1325.2223\n",
      "Epoch 179/1000\n",
      "22753/22753 [==============================] - 8s 340us/sample - loss: 352.8238 - val_loss: 1407.2124\n",
      "Epoch 180/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 362.7941 - val_loss: 1307.5399\n",
      "Epoch 181/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 338.1875 - val_loss: 1383.2837\n",
      "Epoch 182/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 343.2602 - val_loss: 1676.0028\n",
      "Epoch 183/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 369.0764 - val_loss: 1173.7109\n",
      "Epoch 184/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 349.0649 - val_loss: 1478.6366\n",
      "Epoch 185/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 325.3814 - val_loss: 2470.3763\n",
      "Epoch 186/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 431.6766 - val_loss: 1491.3996\n",
      "Epoch 187/1000\n",
      "22753/22753 [==============================] - 8s 338us/sample - loss: 307.1167 - val_loss: 1157.2387\n",
      "Epoch 188/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 375.9512 - val_loss: 2045.5473\n",
      "Epoch 189/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 340.1528 - val_loss: 1181.6182\n",
      "Epoch 190/1000\n",
      "22753/22753 [==============================] - 8s 335us/sample - loss: 311.9980 - val_loss: 1142.0744\n",
      "Epoch 191/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 314.5741 - val_loss: 1237.4665\n",
      "Epoch 192/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 326.2549 - val_loss: 1280.0179\n",
      "Epoch 193/1000\n",
      "22753/22753 [==============================] - 8s 334us/sample - loss: 309.4381 - val_loss: 1228.8653\n",
      "Epoch 194/1000\n",
      "22753/22753 [==============================] - 8s 338us/sample - loss: 344.4684 - val_loss: 1291.4736\n",
      "Epoch 195/1000\n",
      "22753/22753 [==============================] - 8s 336us/sample - loss: 291.7435 - val_loss: 1234.7604\n",
      "Epoch 196/1000\n",
      "22753/22753 [==============================] - 8s 341us/sample - loss: 320.3047 - val_loss: 1347.9583\n",
      "Epoch 197/1000\n",
      "22753/22753 [==============================] - 8s 337us/sample - loss: 318.9909 - val_loss: 1859.9046\n",
      "Epoch 00197: early stopping\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import concatenate, ZeroPadding2D, Add, add, Input, Conv2D, MaxPooling2D, BatchNormalization, Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.initializers import Constant\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "dropout_rate=0\n",
    "resolution = 64\n",
    "channels = 1\n",
    "target=\"/special/jbpark/TabS6illumdata/TabS6_facepos/train_dataset/\"\n",
    "model_dir = \"/special/jbpark/TabS6Model\"\n",
    "\n",
    "# Left Eye\n",
    "input1 = Input(shape=(64, 64,channels), name='left_eye')\n",
    "x = Conv2D(32, (3, 3), padding = 'same', activation = 'relu')(input1)\n",
    "x = MaxPooling2D(pool_size = (2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(x)\n",
    "x = MaxPooling2D(pool_size = (2, 2))(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(x)\n",
    "left_eye = MaxPooling2D(pool_size = (2, 2))(x)\n",
    "left_eye = Flatten()(left_eye)\n",
    "\n",
    "# Right Eye\n",
    "input2 = Input(shape=(64, 64,channels), name='right_eye')\n",
    "x = Conv2D(32, (3, 3), padding = 'same', activation = 'relu')(input2)\n",
    "x = MaxPooling2D(pool_size = (2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), padding = 'same', activation = 'relu')(x)\n",
    "x = MaxPooling2D(pool_size = (2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), padding = 'same', activation = 'relu')(x)\n",
    "right_eye = MaxPooling2D(pool_size = (2, 2), padding='same')(x)\n",
    "right_eye = Flatten()(right_eye)\n",
    "\n",
    "# Eyes\n",
    "eyes = concatenate([left_eye, right_eye])\n",
    "fc1 = Dense(256, activation='relu')(eyes)\n",
    "fc1 = Dropout(rate=dropout_rate)(fc1)\n",
    "\n",
    "# Facepos\n",
    "input5 = Input(shape=(1, 1, 2), name='facepos')\n",
    "facepos = Flatten()(input5)\n",
    "\n",
    "#Euler\n",
    "input3 = Input(shape=(1, 1, 3), name='euler')\n",
    "euler = Dense(3, activation='relu')(input3)\n",
    "euler = Flatten()(euler)\n",
    "\n",
    "# Face Grid\n",
    "input4 = Input(shape=(25, 25, 1), name='face_grid')\n",
    "face_grid = Flatten()(input4)\n",
    "face_grid = Dense(16, activation='relu')(face_grid)\n",
    "\n",
    "head_pose = concatenate([face_grid, euler, facepos])\n",
    "fc_f1 = Dense(64, activation='relu')(head_pose)\n",
    "\n",
    "# FC2, FC3\n",
    "fc2 = Dense(128, activation='relu')(fc1)\n",
    "fc2 = concatenate([fc2, fc_f1])\n",
    "fc3 = Dense(2, activation='linear', name='pred')(fc2)\n",
    "print(tf.keras.backend.shape(fc3))\n",
    "print(tf.keras.backend.shape(facepos))\n",
    "fc3 = add([fc3,facepos])\n",
    "pred = fc3\n",
    "\n",
    "model = Model(inputs=[input1, input2, input3, input4, input5], outputs=[pred])\n",
    "\n",
    "tf.distribute.MirroredStrategy()\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr=1e-3))\n",
    "model.summary()\n",
    "\n",
    "which = \"all\"\n",
    "\n",
    "gaze_point = np.load(target+\"gaze_point.npy\")\n",
    "left_eye = np.load(target+\"left_eye.npy\").reshape(-1,resolution,resolution,channels)\n",
    "right_eye = np.load(target+\"right_eye.npy\").reshape(-1,resolution,resolution,channels)\n",
    "face_grid = np.load(target+\"face_grid.npy\").reshape(-1,25,25,1)\n",
    "euler = np.load(target+\"euler.npy\").reshape(-1,1,1,3)\n",
    "facepos = np.load(target+\"facepos.npy\").reshape(-1,1,1,2)\n",
    "\n",
    "epoch = 1000\n",
    "Path(model_dir+'/checkpoint').mkdir(parents=True, exist_ok=True)\n",
    "mc = ModelCheckpoint(model_dir+'/checkpoint/illum_facepos.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "hist = model.fit([left_eye,right_eye, euler, face_grid, facepos],gaze_point, validation_split=0.1,epochs=epoch, callbacks=[es, mc])\n",
    "\n",
    "Path(model_dir+'/MSEmodels').mkdir(parents=True, exist_ok=True)\n",
    "model.save(model_dir+'/MSEmodels/illum_facepos.h5')\n",
    "\n",
    "K.clear_session()\n",
    "%xdel -n gaze_point\n",
    "%xdel -n face\n",
    "%xdel -n left_eye\n",
    "%xdel -n right_eye\n",
    "%xdel -n face_grid\n",
    "%xdel -n euler\n",
    "gc.collect()\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "403/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 465us/sample - loss: 469.6642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Tested on Model tabs6 result: 0.1012351605902097 elapsed time: 0.22767346701584756\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "import gc\n",
    "from tensorflow.keras.layers import concatenate, add, Input, Conv2D, MaxPooling2D, BatchNormalization, Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.initializers import Constant\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import time\n",
    "\n",
    "resolution=64\n",
    "target=\"/special/jbpark/TabS6data/TabS6_facepos/test_dataset/\"\n",
    "model_dir = \"/special/jbpark/TabS6Model\"\n",
    "\n",
    "gaze_point = np.load(target+\"gaze_point.npy\")\n",
    "left_eye = np.load(target+\"left_eye.npy\").reshape(-1,resolution,resolution,1)\n",
    "right_eye = np.load(target+\"right_eye.npy\").reshape(-1,resolution,resolution,1)\n",
    "euler = np.load(target+\"euler.npy\").reshape(-1,1,1,3)\n",
    "\n",
    "#for loop in [\"1\",\"2\",\"3\",\"4\",\"5\",\"_all\"]:\n",
    "result=[]\n",
    "# [\"nodata1\",\"noglass\",\"nodata3\",\"nodata4\",\"nodata5\",\"all\"]:\n",
    "new_model = load_model(model_dir+'/MSEmodels/facepos.h5')\n",
    "start_time = time.perf_counter()\n",
    "result = new_model.evaluate([left_eye,right_eye,euler],gaze_point, batch_size=32)\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "result = (math.sqrt(result)/1440)*7\n",
    "print(\"Data Tested on Model tabs6 result: \"+str(result)+\" elapsed time: \"+ str(elapsed_time))\n",
    "\n",
    "K.clear_session()\n",
    "%xdel -n gaze_point\n",
    "%xdel -n face\n",
    "%xdel -n left_eye\n",
    "%xdel -n right_eye\n",
    "%xdel -n face_grid\n",
    "gc.collect()\n",
    "%reset -f "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### if you get error with toco_protos or toco run the python code with terminal or convert whole file to .py file then run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: facepos.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d2f803052eb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mkeras_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'facepos.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Convert to TensorFlow Lite model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Convert the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/tensorflow20/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/envs/tensorflow20/lib/python3.7/site-packages/tensorflow_core/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     81\u001b[0m                   (export_dir,\n\u001b[1;32m     82\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: facepos.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "model_dir = \"/special/jbpark/TabS6Model/MSEmodels/\"\n",
    "keras_file = 'illum_facepos.h5'\n",
    "# Convert to TensorFlow Lite model.\n",
    "model = load_model(keras_file)\n",
    "\n",
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TF Lite model.\n",
    "with tf.io.gfile.GFile('tflite/illum_facepos.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'left_eye',\n",
       "  'index': 4,\n",
       "  'shape': array([ 1, 64, 64,  1], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'euler',\n",
       "  'index': 1,\n",
       "  'shape': array([1, 1, 1, 3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'facepos',\n",
       "  'index': 3,\n",
       "  'shape': array([1, 1, 1, 2], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'face_grid',\n",
       "  'index': 2,\n",
       "  'shape': array([ 1, 25, 25,  1], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)},\n",
       " {'name': 'right_eye',\n",
       "  'index': 56,\n",
       "  'shape': array([ 1, 64, 64,  1], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0)}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tflite = tf.lite.Interpreter(model_path=\"/special/jbpark/TabS6Model/checkpoint/tflite/illum_facepos.tflite\")\n",
    "tflite.get_input_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.0",
   "language": "python",
   "name": "tensorflow20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
